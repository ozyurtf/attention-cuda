## Attention Mechanism in CUDA

In this project, attention mechanism is implemented in CUDA by utilizing shared memory, coalesced memory, warp shuffle, and tiling. 

![GPU Memory Architecture](figures/gpu-memory-architecture.png)

![Attention Mechanism](figures/attention-mechanism.png)

### Matrix Multiplication 

![Matrix Multiplication](figures/matmul-tiled.png)

### Softmax 

### Transpose 

