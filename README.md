## Attention Mechanism in CUDA

In this project, attention mechanism is implemented in CUDA by utilizing shared memory, coalesced memory, warp shuffle, and tiling. 

<img src="figures/gpu-memory-architecture.png" alt="GPU Memory Architecture" width="300"/>

### Matrix Multiplication 

![Matrix Multiplication](figures/matmul-tiled.png)

### Softmax 

### Transpose 

### Multi-Head Attention Mechanism

![Attention Mechanism](figures/attention-mechanism.png)

